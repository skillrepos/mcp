# mcp_server.py – FastMCP 2.10.4-compatible server
from mcp.server.fastmcp import FastMCP

# ANSI color codes
BLUE = "\033[94m"
GREEN = "\033[92m"
RESET = "\033[0m"

# Create a FastMCP server instance with a service name
server = FastMCP()

# ───────────────────────────────────────────────
# Prompt handlers – return single message templates
# These are used by clients to fetch structured prompts
# ───────────────────────────────────────────────

@server.prompt("summarize")
def prompt_summarize(text: str) -> dict:
    """You are a helpful assistant. Summarize the following text in one sentence."""
    print(f"{BLUE}[PROMPT REQUEST] summarize called with text: {text!r}{RESET}")
    result = {
        "role": "user",
        "content": (
            "You are a helpful assistant. Summarize the following text in one sentence.\n\n"
            f"{text}"
        )
    }
    print(f"{GREEN}[PROMPT RETURN] summarize response: {result}{RESET}")
    return result

@server.prompt("reword")
def prompt_reword(text: str) -> dict:
    """You are a helpful assistant. Reword the following text using clearer and simpler language."""
    print(f"{BLUE}[PROMPT REQUEST] reword called with text: {text!r}{RESET}")
    result = {
        "role": "user",
        "content": (
            "You are a helpful assistant. Reword the following text using clearer and simpler language.\n\n"
            f"{text}"
        )
    }
    print(f"{GREEN}[PROMPT RETURN] reword response: {result}{RESET}")
    return result

@server.prompt("expand")
def prompt_expand(text: str) -> dict:
    """You are a helpful assistant. Expand on the following idea with additional detail and explanation."""
    print(f"{BLUE}[PROMPT REQUEST] expand called with text: {text!r}{RESET}")
    result = {
        "role": "user",
        "content": (
            "You are a helpful assistant. Expand on the following idea with additional detail and explanation.\n\n"
            f"{text}"
        )
    }
    print(f"{GREEN}[PROMPT RETURN] expand response: {result}{RESET}")
    return result

# ───────────────────────────────────────────────
# Tool handlers – used to expose tool names to the client
# These stubs are for visibility only; they do not perform actions
# ───────────────────────────────────────────────

@server.tool("summarize")
def summarize_tool(text: str) -> str:
    print(f"{BLUE}[TOOL REQUEST] summarize_tool received input: {text!r}{RESET}")
    print(f"{GREEN}[TOOL RETURN] summarize_tool returning: {text!r}{RESET}")
    return text

@server.tool("reword")
def reword_tool(text: str) -> str:
    print(f"{BLUE}[TOOL REQUEST] reword_tool received input: {text!r}{RESET}")
    print(f"{GREEN}[TOOL RETURN] reword_tool returning: {text!r}{RESET}")
    return text

@server.tool("expand")
def expand_tool(text: str) -> str:
    print(f"{BLUE}[TOOL REQUEST] expand_tool received input: {text!r}{RESET}")
    print(f"{GREEN}[TOOL RETURN] expand_tool returning: {text!r}{RESET}")
    return text

# ───────────────────────────────────────────────
# Resource – lets the client discover the model to use
# ───────────────────────────────────────────────

@server.resource("resource://model")
def model_name():
    print(f"{BLUE}[RESOURCE REQUEST] model_name requested{RESET}")
    result = {"model": "llama3.2:latest"}
    print(f"{GREEN}[RESOURCE RETURN] model_name response: {result}{RESET}")
    return result

# ───────────────────────────────────────────────
# Entry point – start the FastMCP server with streamable HTTP
# ───────────────────────────────────────────────

if __name__ == "__main__":
    print(f"{BLUE}Starting FastMCP server on streamable HTTP...{RESET}")
    server.run(transport="streamable-http")


